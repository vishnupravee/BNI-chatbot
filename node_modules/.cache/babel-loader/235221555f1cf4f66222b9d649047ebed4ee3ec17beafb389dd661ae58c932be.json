{"ast":null,"code":"// import React, { useState, useEffect, useRef, useCallback } from 'react';\n// import ReactMarkdown from 'react-markdown';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n// import './App.css';\n\n// // --- SVG Icons ---\n// const UserIcon = () => ( <svg width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"#d9d9e9\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z\"/></svg> );\n// const BotIcon = ({ logoSrc }) => ( <img src={logoSrc} alt=\"bot icon\" style={{ width: '30px', height: '30px', borderRadius: '4px' }} /> );\n// const MicrophoneIcon = () => ( <svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" stroke=\"currentColor\" strokeWidth=\"1.5\" strokeLinecap=\"round\" strokeLinejoin=\"round\"><path d=\"M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z\"></path><path d=\"M19 10v2a7 7 0 0 1-14 0v-2\"></path><line x1=\"12\" y1=\"19\" x2=\"12\" y2=\"22\"></line></svg> );\n\n// // 1. --- NEW SVG ICON FOR STOP BUTTON ---\n// const StopIcon = () => (\n//   <svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"currentColor\" xmlns=\"http://www.w3.org/2000/svg\">\n//     <path d=\"M6 6h12v12H6V6z\"/>\n//   </svg>\n// );\n\n// function App() {\n//   const [messages, setMessages] = useState([]);\n//   const [input, setInput] = useState('');\n//   // 2. --- NEW STATE TO TRACK IF BOT IS SPEAKING ---\n//   const [isBotSpeaking, setIsBotSpeaking] = useState(false);\n//   const chatWindowRef = useRef(null);\n\n//   const { transcript, listening, resetTranscript, browserSupportsSpeechRecognition } = useSpeechRecognition();\n\n//   // This needs to be wrapped in useCallback to satisfy the linter warning in the next useEffect\n//   const handleSend = useCallback(async (messageToSend, isVoiceInput = false) => {\n//     if (messageToSend.trim() === '') return;\n\n//     setInput('');\n//     resetTranscript();\n\n//     const userMessage = { text: messageToSend, sender: 'user' };\n//     setMessages(prevMessages => [...prevMessages, userMessage]);\n\n//     try {\n//       const response = await fetch('http://localhost:5001/api/chat', {\n//         method: 'POST',\n//         headers: { 'Content-Type': 'application/json' },\n//         body: JSON.stringify({ message: messageToSend }),\n//       });\n\n//       const data = await response.json();\n//       const botMessage = { text: data.reply, sender: 'bot' };\n//       setMessages(prevMessages => [...prevMessages, botMessage]);\n\n//       if (isVoiceInput) {\n//         window.speechSynthesis.cancel();\n//         const utterance = new SpeechSynthesisUtterance(data.reply);\n\n//         // 3. --- MANAGE SPEAKING STATE WITH EVENTS ---\n//         utterance.onstart = () => setIsBotSpeaking(true);\n//         // This onend event handles both natural finishes and manual cancellations\n//         utterance.onend = () => setIsBotSpeaking(false);\n\n//         window.speechSynthesis.speak(utterance);\n//       }\n\n//     } catch (error) {\n//       console.error('Error fetching bot reply:', error);\n//       setIsBotSpeaking(false); // Ensure state is reset on error\n//       const errorMessage = { text: 'Sorry, I am having trouble connecting.', sender: 'bot' };\n//       setMessages(prevMessages => [...prevMessages, errorMessage]);\n//     }\n//   }, [resetTranscript]);\n\n//   useEffect(() => {\n//     if (!listening && transcript) {\n//       handleSend(transcript, true);\n//     }\n//   }, [listening, transcript, handleSend]);\n\n//   useEffect(() => { window.speechSynthesis.getVoices(); }, []);\n//   useEffect(() => { setInput(transcript); }, [transcript]);\n//   useEffect(() => {\n//     if (chatWindowRef.current) { chatWindowRef.current.scrollTop = chatWindowRef.current.scrollHeight; }\n//   }, [messages]);\n\n//   const handleNewChat = () => {\n//     window.speechSynthesis.cancel(); // Stop any speech on new chat\n//     setIsBotSpeaking(false);\n//     setMessages([]);\n//     resetTranscript();\n//     setInput('');\n//   };\n\n//   // 4. --- NEW FUNCTION TO HANDLE VOICE STOP ---\n//   const handleStopVoice = () => {\n//     window.speechSynthesis.cancel();\n//     setIsBotSpeaking(false);\n//   };\n\n//   const handleTextSubmit = () => {\n//     if (input.trim() === '') return;\n//     handleSend(input, false);\n//   };\n\n//   const handleVoiceRecording = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening();\n//     } else {\n//       resetTranscript();\n//       SpeechRecognition.startListening({ continuous: false });\n//     }\n//   };\n\n//   if (!browserSupportsSpeechRecognition) {\n//     return <span>Sorry, your browser does not support speech recognition.</span>;\n//   }\n\n//   return (\n//     <div className=\"App\">\n//       <div className=\"sidebar\">\n//         <div className=\"new-chat-button\" onClick={handleNewChat}>\n//           + New Chat\n//         </div>\n//       </div>\n//       <div className=\"main-content\">\n//         <div className=\"chat-window\" ref={chatWindowRef}>\n//           {messages.length === 0 ? (\n//             <div className=\"welcome-screen\">\n//               <img src=\"BNI.png\" className=\"welcome-logo\" alt=\"logo\" />\n//               <h2>How can I help you today?</h2>\n//             </div>\n//           ) : (\n//             messages.map((msg, index) => (\n//               <div key={index} className={`message-wrapper ${msg.sender}`}>\n//                 <div className=\"message\">\n//                   <div className=\"message-icon\">\n//                     {msg.sender === 'user' ? <UserIcon /> : <BotIcon logoSrc=\"BNI.png\" />}\n//                   </div>\n//                   <div className=\"message-content\">\n//                     <ReactMarkdown>{msg.text}</ReactMarkdown>\n//                   </div>\n//                 </div>\n//               </div>\n//             ))\n//           )}\n//         </div>\n//         <div className=\"chat-input-container\">\n//           <div className=\"chat-input\">\n//             <textarea\n//               value={input}\n//               onChange={(e) => setInput(e.target.value)}\n//               placeholder={listening ? \"Listening...\" : \"Ask BNI-ChatBot...\"}\n//               onKeyPress={(e) => {\n//                 if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); handleTextSubmit(); }\n//               }}\n//             />\n//             {/* 5. --- CONDITIONAL RENDERING OF BUTTONS --- */}\n//             {isBotSpeaking ? (\n//               <button onClick={handleStopVoice} className=\"stop-button\">\n//                 <StopIcon />\n//               </button>\n//             ) : (\n//               <button onClick={handleVoiceRecording} className={`mic-button ${listening ? 'listening' : ''}`}>\n//                 <MicrophoneIcon />\n//               </button>\n//             )}\n//             <button onClick={handleTextSubmit} className=\"send-button\" disabled={!input.trim()}>\n//               â†‘\n//             </button>\n//           </div>\n//           <p className=\"footer-text\">BNI-ChatBot can make mistakes. Consider checking important information.</p>\n//         </div>\n//       </div>\n//     </div>\n//   );\n// }\n\n// export default App;","map":{"version":3,"names":[],"sources":["C:/Users/dell/bnichat-bot/frontend/src/App.js"],"sourcesContent":["// import React, { useState, useEffect, useRef, useCallback } from 'react';\n// import ReactMarkdown from 'react-markdown';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n// import './App.css';\n\n// // --- SVG Icons ---\n// const UserIcon = () => ( <svg width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"#d9d9e9\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z\"/></svg> );\n// const BotIcon = ({ logoSrc }) => ( <img src={logoSrc} alt=\"bot icon\" style={{ width: '30px', height: '30px', borderRadius: '4px' }} /> );\n// const MicrophoneIcon = () => ( <svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" stroke=\"currentColor\" strokeWidth=\"1.5\" strokeLinecap=\"round\" strokeLinejoin=\"round\"><path d=\"M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z\"></path><path d=\"M19 10v2a7 7 0 0 1-14 0v-2\"></path><line x1=\"12\" y1=\"19\" x2=\"12\" y2=\"22\"></line></svg> );\n\n// // 1. --- NEW SVG ICON FOR STOP BUTTON ---\n// const StopIcon = () => (\n//   <svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"currentColor\" xmlns=\"http://www.w3.org/2000/svg\">\n//     <path d=\"M6 6h12v12H6V6z\"/>\n//   </svg>\n// );\n\n\n// function App() {\n//   const [messages, setMessages] = useState([]);\n//   const [input, setInput] = useState('');\n//   // 2. --- NEW STATE TO TRACK IF BOT IS SPEAKING ---\n//   const [isBotSpeaking, setIsBotSpeaking] = useState(false);\n//   const chatWindowRef = useRef(null);\n\n//   const { transcript, listening, resetTranscript, browserSupportsSpeechRecognition } = useSpeechRecognition();\n\n//   // This needs to be wrapped in useCallback to satisfy the linter warning in the next useEffect\n//   const handleSend = useCallback(async (messageToSend, isVoiceInput = false) => {\n//     if (messageToSend.trim() === '') return;\n\n//     setInput('');\n//     resetTranscript();\n\n//     const userMessage = { text: messageToSend, sender: 'user' };\n//     setMessages(prevMessages => [...prevMessages, userMessage]);\n    \n//     try {\n//       const response = await fetch('http://localhost:5001/api/chat', {\n//         method: 'POST',\n//         headers: { 'Content-Type': 'application/json' },\n//         body: JSON.stringify({ message: messageToSend }),\n//       });\n\n//       const data = await response.json();\n//       const botMessage = { text: data.reply, sender: 'bot' };\n//       setMessages(prevMessages => [...prevMessages, botMessage]);\n\n//       if (isVoiceInput) {\n//         window.speechSynthesis.cancel();\n//         const utterance = new SpeechSynthesisUtterance(data.reply);\n        \n//         // 3. --- MANAGE SPEAKING STATE WITH EVENTS ---\n//         utterance.onstart = () => setIsBotSpeaking(true);\n//         // This onend event handles both natural finishes and manual cancellations\n//         utterance.onend = () => setIsBotSpeaking(false);\n        \n//         window.speechSynthesis.speak(utterance);\n//       }\n\n//     } catch (error) {\n//       console.error('Error fetching bot reply:', error);\n//       setIsBotSpeaking(false); // Ensure state is reset on error\n//       const errorMessage = { text: 'Sorry, I am having trouble connecting.', sender: 'bot' };\n//       setMessages(prevMessages => [...prevMessages, errorMessage]);\n//     }\n//   }, [resetTranscript]);\n\n//   useEffect(() => {\n//     if (!listening && transcript) {\n//       handleSend(transcript, true);\n//     }\n//   }, [listening, transcript, handleSend]);\n\n//   useEffect(() => { window.speechSynthesis.getVoices(); }, []);\n//   useEffect(() => { setInput(transcript); }, [transcript]);\n//   useEffect(() => {\n//     if (chatWindowRef.current) { chatWindowRef.current.scrollTop = chatWindowRef.current.scrollHeight; }\n//   }, [messages]);\n\n//   const handleNewChat = () => {\n//     window.speechSynthesis.cancel(); // Stop any speech on new chat\n//     setIsBotSpeaking(false);\n//     setMessages([]);\n//     resetTranscript();\n//     setInput('');\n//   };\n  \n//   // 4. --- NEW FUNCTION TO HANDLE VOICE STOP ---\n//   const handleStopVoice = () => {\n//     window.speechSynthesis.cancel();\n//     setIsBotSpeaking(false);\n//   };\n\n//   const handleTextSubmit = () => {\n//     if (input.trim() === '') return;\n//     handleSend(input, false);\n//   };\n\n//   const handleVoiceRecording = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening();\n//     } else {\n//       resetTranscript();\n//       SpeechRecognition.startListening({ continuous: false });\n//     }\n//   };\n\n//   if (!browserSupportsSpeechRecognition) {\n//     return <span>Sorry, your browser does not support speech recognition.</span>;\n//   }\n\n//   return (\n//     <div className=\"App\">\n//       <div className=\"sidebar\">\n//         <div className=\"new-chat-button\" onClick={handleNewChat}>\n//           + New Chat\n//         </div>\n//       </div>\n//       <div className=\"main-content\">\n//         <div className=\"chat-window\" ref={chatWindowRef}>\n//           {messages.length === 0 ? (\n//             <div className=\"welcome-screen\">\n//               <img src=\"BNI.png\" className=\"welcome-logo\" alt=\"logo\" />\n//               <h2>How can I help you today?</h2>\n//             </div>\n//           ) : (\n//             messages.map((msg, index) => (\n//               <div key={index} className={`message-wrapper ${msg.sender}`}>\n//                 <div className=\"message\">\n//                   <div className=\"message-icon\">\n//                     {msg.sender === 'user' ? <UserIcon /> : <BotIcon logoSrc=\"BNI.png\" />}\n//                   </div>\n//                   <div className=\"message-content\">\n//                     <ReactMarkdown>{msg.text}</ReactMarkdown>\n//                   </div>\n//                 </div>\n//               </div>\n//             ))\n//           )}\n//         </div>\n//         <div className=\"chat-input-container\">\n//           <div className=\"chat-input\">\n//             <textarea\n//               value={input}\n//               onChange={(e) => setInput(e.target.value)}\n//               placeholder={listening ? \"Listening...\" : \"Ask BNI-ChatBot...\"}\n//               onKeyPress={(e) => {\n//                 if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); handleTextSubmit(); }\n//               }}\n//             />\n//             {/* 5. --- CONDITIONAL RENDERING OF BUTTONS --- */}\n//             {isBotSpeaking ? (\n//               <button onClick={handleStopVoice} className=\"stop-button\">\n//                 <StopIcon />\n//               </button>\n//             ) : (\n//               <button onClick={handleVoiceRecording} className={`mic-button ${listening ? 'listening' : ''}`}>\n//                 <MicrophoneIcon />\n//               </button>\n//             )}\n//             <button onClick={handleTextSubmit} className=\"send-button\" disabled={!input.trim()}>\n//               â†‘\n//             </button>\n//           </div>\n//           <p className=\"footer-text\">BNI-ChatBot can make mistakes. Consider checking important information.</p>\n//         </div>\n//       </div>\n//     </div>\n//   );\n// }\n\n// export default App;\n\n"],"mappings":"AAAA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAGA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}